{
 "metadata": {
  "name": "",
  "signature": "sha256:ca1ae94e6f2d46623e4e288f97c795565187126e4f20c27effb748336841353c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import sys\n",
      "import string\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from __future__ import print_function\n",
      "\n",
      "# turn of data table rendering\n",
      "pd.set_option('display.notebook_repr_html', False)\n",
      "sns.set_palette(['#00A99D', '#F5CA0C', '#B6129F', '#76620C', '#095C57'])\n",
      "sys.version"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 216,
       "text": [
        "'3.4.1 |Anaconda 2.1.0 (64-bit)| (default, Sep 24 2014, 18:32:42) [MSC v.1600 64 bit (AMD64)]'"
       ]
      }
     ],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load 200 tweets from kdnuggets and analyticbridge (n=400)\n",
      "df = pd.read_csv('data/tweets.csv')\n",
      "df.screen_name.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 217,
       "text": [
        "analyticbridge    200\n",
        "kdnuggets         200\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.screen_name[331], df.tweet[331]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 245,
       "text": [
        "('analyticbridge',\n",
        " 'Three myths about data scientists and big data http://t.co/EtzjR4pdbH')"
       ]
      }
     ],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# In order to perform machine learning on text documents, we first \n",
      "# need to turn the text content into numerical feature vectors.\n",
      "count_vect = CountVectorizer()\n",
      "X_train_counts = count_vect.fit_transform(df.tweet)\n",
      "X_train_counts.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 279,
       "text": [
        "(400, 2098)"
       ]
      }
     ],
     "prompt_number": 279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the feature index for the word 'myths'\n",
      "# The index value of a word in the vocabulary is linked to \n",
      "# its frequency in the whole training corpus.\n",
      "count_vect.vocabulary_.get(u'myths')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 308,
       "text": [
        "1229"
       ]
      }
     ],
     "prompt_number": 308
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Transform to Term Frequencies\n",
      "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
      "X_train_tf = tf_transformer.transform(X_train_counts)\n",
      "X_train_tf.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 309,
       "text": [
        "(400, 2098)"
       ]
      }
     ],
     "prompt_number": 309
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Non zero values\n",
      "X_train_tf.data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 310,
       "text": [
        "0.24253562503633297"
       ]
      }
     ],
     "prompt_number": 310
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "clf = MultinomialNB().fit(X_train_tfidf, df.screen_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 319
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docs_new = ['NYC DSA Data Science Bootcamp, Jun 1 \u2013 Aug 21 http://bit.ly/1yxtbs5', \n",
      "            '@IQuantNY mapping the #sharing #economy: @Airbnb #NYC Footprint - Manhattan more expensive http://buff.ly/1AsLMv5', \n",
      "            'Why Electric Cars Don\u2019t Have Better Batteries - a sad story of Envia - MIT @TechReview http://buff.ly/1Agl0aE  pic.twitter.com/w1DX6q092O',\n",
      "            'DSC Search Engine for #DataScience - http://bit.ly/17tTFFy' ]\n",
      "X_new_counts = count_vect.transform(docs_new)\n",
      "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
      "\n",
      "predicted = clf.predict(X_new_tfidf)\n",
      "\n",
      "for doc, category in zip(docs_new, predicted):\n",
      "    print('%r => %s' % (doc, category))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'NYC DSA Data Science Bootcamp, Jun 1 \u2013 Aug 21 http://bit.ly/1yxtbs5' => analyticbridge\n",
        "'@IQuantNY mapping the #sharing #economy: @Airbnb #NYC Footprint - Manhattan more expensive http://buff.ly/1AsLMv5' => kdnuggets\n",
        "'Why Electric Cars Don\u2019t Have Better Batteries - a sad story of Envia - MIT @TechReview http://buff.ly/1Agl0aE  pic.twitter.com/w1DX6q092O' => kdnuggets\n",
        "'DSC Search Engine for #DataScience - http://bit.ly/17tTFFy' => analyticbridge\n"
       ]
      }
     ],
     "prompt_number": 322
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}