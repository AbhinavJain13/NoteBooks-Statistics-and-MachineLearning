{
 "metadata": {
  "name": "",
  "signature": "sha256:0e4642e4d7f3030d4b5dd1b9b6de71df8075a8ca7c7b2b7f17d9aa1ec1d4387e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Machine Learning\n",
      "Quite a few machine learning questions focus on predicting an outcome based on a set of features. Linear regression with gradient descent is a supervised learning technique. The machine learns the best fitting linear function from a training set, which it uses to predict outcomes based on feauture values it has not encountered before.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Goal\n",
      "Our goal using Linear Regression with Gradient Descent, is trying to minimize the cost function to get the best predictive equation. In other words, we need to make the sum of the squared differences between the predicted and the actual values as small as possible.\n",
      "\n",
      "$$minimize \\sum_{i=1}^m(y_{predicted}-y_{actual})^2$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Datapoints\n",
      "In our test set, each datapoint has a set of features (input variables) $x_1, x_2, x_n$ that leads to an observed outcome $y$ (output variable). Features are for instance the age, height, weight, and handedness of a baseball player. The outcome could be something like the batting average in the player's career. The datapoints are vectors $1\\ to\\ m$ as shown here:\n",
      "\n",
      "$$\n",
      "\\begin{pmatrix} \\underline{y_{1\\ avg}} \\\\ x_{age} \\\\ x_{height} \\\\ x_{weight} \\\\ x_{hand} \\end{pmatrix}\n",
      "\\begin{pmatrix} \\underline{y_2} \\\\ x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix}\n",
      "\\begin{pmatrix} \\underline{y_3} \\\\ x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix}\n",
      "to\n",
      "\\begin{pmatrix} \\underline{y_m} \\\\ x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix}\n",
      "$$\n",
      "\n",
      "## Parameters\n",
      "We define a set of coefficients, called parameters or weights of the model. A coefficient $\\theta$ (theta) relates to a single feature. Each theta value indicates how important the corresponding feature is, in relation to the other features, when predicting the outcome. A relative large $\\theta_i$ mean that feauture $x_i$ is a big contributor in predicting the outcome. Eventually, the sum of all features times their respective $\\theta$ results in the predicted outcome $h$. The cost function $J(\\Theta)$ (of all theta's combined) is a meassure of how well our set of theta's does in predicting the expected outcome. \n",
      "\n",
      "$$J(\\Theta)=\\frac{1}{m}\\sum_{i=1}^m(h(x^i)-y^i)^2, \\\\\n",
      "h(x^i)=\\sum_{j=0}^n\\theta_jx_j^i\n",
      "$$\n",
      "\n",
      "- $h$ = predicted value\n",
      "- $i$ = data point index\n",
      "- $m$ = number of data points\n",
      "- $j$ = feature index\n",
      "- $n$ = number of features\n",
      "- $x$ = feature\n",
      "\n",
      "## Gradient Descent\n",
      "\n",
      "we can use an algorithm called Gradient Descent."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from scipy import stats\n",
      "import statsmodels.api as sm\n",
      "import math\n",
      "from __future__ import division\n",
      "\n",
      "# turn of data table rendering\n",
      "pd.set_option('display.notebook_repr_html', False)\n",
      "\n",
      "sns.set_palette(['#00A99D', '#F5CA0C', '#B6129F', '#76620C', '#095C57'])\n",
      "np.version.full_version, scipy.version.full_version, \\\n",
      "pd.version.version, sm.version.full_version"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "('1.9.1', '0.14.0', '0.15.2', '0.6.1')"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}